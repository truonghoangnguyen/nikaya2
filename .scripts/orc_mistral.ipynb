{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "export const OCR_SYSTEM_PROMPT = `\n",
    "Convert the following document to markdown.\n",
    "Return only the markdown with no explanation text. Do not include delimiters like '''markdown or '''html.\n",
    "\n",
    "RULES:\n",
    "  - You must include all information on the page. Do not exclude headers, footers, charts, infographics, or subtext.\n",
    "  - Return tables in an HTML format.\n",
    "  - Logos should be wrapped in brackets. Ex: <logo>Coca-Cola<logo>\n",
    "  - Watermarks should be wrapped in brackets. Ex: <watermark>OFFICIAL COPY<watermark>\n",
    "  - Page numbers should be wrapped in brackets. Ex: <page_number>14<page_number> or <page_number>9/22<page_number>\n",
    "  - Prefer using ☐ and ☑ for check boxes.\n",
    "`;\n",
    "\n",
    "export const JSON_EXTRACTION_SYSTEM_PROMPT = `\n",
    "  Extract the following JSON schema from the text and images if provided.\n",
    "  Return only the JSON with no explanation text.\n",
    "`;\n",
    "\n",
    "export const IMAGE_EXTRACTION_SYSTEM_PROMPT = `\n",
    "  Extract the following JSON schema from the image.\n",
    "  Return only the JSON with no explanation text.\n",
    "`;\n",
    "\"\"\"\n",
    "\n",
    "from PyPDF2 import PdfReader, PdfWriter\n",
    "import os\n",
    "\n",
    "def extract_pdf_pages(input_pdf, output_pdf, start_page, end_page):\n",
    "    \"\"\"\n",
    "    Extracts a range of pages from a PDF file and saves them as a new PDF.\n",
    "\n",
    "    Args:\n",
    "        input_pdf: Path to the input PDF file\n",
    "        output_pdf: Path to save the extracted PDF file\n",
    "        start_page: Starting page number (0-based index)\n",
    "        end_page: Ending page number (0-based index, inclusive)\n",
    "    \"\"\"\n",
    "    reader = PdfReader(input_pdf)\n",
    "    writer = PdfWriter()\n",
    "\n",
    "    # Validate page range\n",
    "    total_pages = len(reader.pages)\n",
    "    if start_page < 0 or end_page >= total_pages or start_page > end_page:\n",
    "        raise ValueError(f\"Invalid page range. PDF has {total_pages} pages.\")\n",
    "\n",
    "    # Add selected pages to the new PDF\n",
    "    for page_num in range(start_page, end_page + 1):\n",
    "        writer.add_page(reader.pages[page_num])\n",
    "\n",
    "    # Save the new PDF\n",
    "    with open(output_pdf, \"wb\") as output_file:\n",
    "        writer.write(output_file)\n",
    "\n",
    "    print(f\"Created PDF with pages {start_page+1} to {end_page+1} at {output_pdf}\")\n",
    "\n",
    "filename = '../../docsource/trungbo-eng-nanamoli-bodhi2.out1.pdf'\n",
    "# 1, 4, 58\n",
    "# 2, 59, 73\n",
    "# 3, 435, 814\n",
    "\n",
    "args = {\"output_pdf\": f'../../docsource/trungbo-eng-nanamoli-bodhi.part{0}.pdf', \"start_page\": 11, \"end_page\": 73}\n",
    "args = {\"output_pdf\": f'../../docsource/trungbo-eng-nanamoli-bodhi.part{1}.pdf', \"start_page\": 77, \"end_page\": 430}\n",
    "# p0=\"https://drive.usercontent.google.com/u/0/uc?id=1dOGYtQABuCOlVdY8WmLlZJShG1jCYKkm&export=download\"\n",
    "p1 = \"https://drive.usercontent.google.com/u/0/uc?id=1ak_jgAYW7S1iD-fgqB63-AYwngVcuFrO&export=download\"\n",
    "# args = {\"output_pdf\": f'../../docsource/trungbo-eng-nanamoli-bodhi.part{2}.pdf', \"start_page\": 435, \"end_page\": 814}\n",
    "# p1 = \"https://drive.usercontent.google.com/u/0/uc?id=1OQyCzluVkULUSNFrhMcEm1dSrc_TFbt0&export=download\"\n",
    "args = {\"output_pdf\": f'../../docsource/trungbo-eng-nanamoli-bodhi.part{3}.pdf', \"start_page\": 819, \"end_page\": 1143}\n",
    "p3=\"https://drive.usercontent.google.com/u/0/uc?id=1MgGtGPfM86NewlhT2P94PMQwbvU18-UZ&export=download\"\n",
    "# args = {\"output_pdf\": f'../../docsource/trungbo-eng-nanamoli-bodhi.part{4}.pdf', \"start_page\": 1147, \"end_page\": 1366}\n",
    "# p4 = \"https://drive.usercontent.google.com/u/0/uc?id=1B7MzZsamRaO31v2hWjpJTEKdrMWeM1Z5&export=download\"\n",
    "extract_pdf_pages('../../docsource/trungbo-eng-nanamoli-bodhi2.pdf', **args)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# step 2 : mistral for ocr\n",
    "from mistralai import Mistral\n",
    "import os\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "\n",
    "load_dotenv(find_dotenv(), override=True)\n",
    "\n",
    "api_key = os.environ.get(\"MISTRALAI_KEY\")\n",
    "client = Mistral(api_key=api_key)\n",
    "\n",
    "ocr_response = client.ocr.process(\n",
    "    model=\"mistral-ocr-latest\",\n",
    "    document={\n",
    "        \"type\": \"document_url\",\n",
    "        \"document_url\": \"https://drive.usercontent.google.com/u/0/uc?id=1MgGtGPfM86NewlhT2P94PMQwbvU18-UZ&export=download\"\n",
    "    },\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(ocr_response.pages[0].markdown)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# step 3: write to markdown\n",
    "import re\n",
    "def is_new_paragraph_start(first_line):\n",
    "    \"\"\"Kiểm tra xem dòng đầu tiên có vẻ là bắt đầu đoạn văn mới không.\"\"\"\n",
    "    if not first_line: # Trang trống\n",
    "        return True\n",
    "    first_char = first_line[0]\n",
    "    return first_char.isupper() or first_char.isdigit() or first_char == '#' # Đơn giản: bắt đầu bằng chữ hoa có thể là đoạn mới (cần tinh chỉnh)\n",
    "\n",
    "\n",
    "\n",
    "def replace_newline_split_join_no_generator(text):\n",
    "    \"\"\"\n",
    "    Split and join version, but without using a generator expression.\n",
    "    Potentially a bit more readable, and may be slightly more performant for\n",
    "    *very* large strings (due to avoiding repeated string concatenation)\n",
    "    \"\"\"\n",
    "    parts = text.split(\"\\n\\n\")\n",
    "    modified_parts = []\n",
    "    for part in parts:\n",
    "        modified_parts.append(part.replace(\"\\n\", \"\\n\\n\"))\n",
    "    return \"\\n\\n\".join(modified_parts)\n",
    "\n",
    "output_file=\"trungbo-eng-nanamoli-bodhi.part3.md\"\n",
    "with open(output_file, \"w\", encoding=\"utf-8\") as f:\n",
    "    for i, page in enumerate(ocr_response.pages):\n",
    "        txt = page.markdown# .replace(\"\\n\", \"\\n\\n\")\n",
    "        txt = replace_newline_split_join_no_generator(txt)\n",
    "        f.write(txt)\n",
    "        if i < len(ocr_response.pages) - 1: # Không thêm vào trang cuối\n",
    "            next_page_first_line = ocr_response.pages[i+1].markdown.strip().splitlines()[0] if ocr_response.pages[i+1].markdown.strip().splitlines() else \"\"\n",
    "            if is_new_paragraph_start(next_page_first_line):\n",
    "                f.write(\"\\n\\n\") # Hoặc f.write(\"\\n---\\n\")\n",
    "            else:\n",
    "                f.write(\"\\n\") # Hoặc không thêm gì cả, tùy thử nghiệm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created file: nm-p3/101-at-devadaha.md\n",
      "Created file: nm-p3/102-the-five-and-three.md\n",
      "Created file: nm-p3/103-what-do-you-think-about-me.md\n",
      "Created file: nm-p3/104-at-samagama.md\n",
      "Created file: nm-p3/105-to-sunakkhatta.md\n",
      "Created file: nm-p3/106-the-way-to-the-imperturbable.md\n",
      "Created file: nm-p3/107-to-ganaka-moggallana.md\n",
      "Created file: nm-p3/108-with-gopaka-moggallana.md\n",
      "Created file: nm-p3/109-the-greater-discourse-on-the-full-moon-night.md\n",
      "Created file: nm-p3/110-the-shorter-discourse-on-the-full-moon-night.md\n",
      "Created file: nm-p3/111-one-by-one-as-they-occurred.md\n",
      "Created file: nm-p3/112-the-sixfold-purity.md\n",
      "Created file: nm-p3/113-the-true-man.md\n",
      "Created file: nm-p3/114-to-be-cultivated-and-not-to-be-cultivated.md\n",
      "Created file: nm-p3/115-the-many-kinds-of-elements.md\n",
      "Created file: nm-p3/116-isigili-the-gullet-of-the-seers.md\n",
      "Created file: nm-p3/117-the-great-forty.md\n",
      "Created file: nm-p3/118-mindfulness-of-breathing.md\n",
      "Created file: nm-p3/119-mindfulness-of-the-body.md\n",
      "Created file: nm-p3/120-reappearance-by-aspiration.md\n",
      "Created file: nm-p3/121-the-shorter-discourse-on-voidness.md\n",
      "Created file: nm-p3/122-the-greater-discourse-on-voidness.md\n",
      "Created file: nm-p3/123-wonderful-and-marvellous.md\n",
      "Created file: nm-p3/124-bakkula.md\n",
      "Created file: nm-p3/125-the-grade-of-the-tamed.md\n",
      "Created file: nm-p3/126-bhumija.md\n",
      "Created file: nm-p3/127-anuruddha.md\n",
      "Created file: nm-p3/128-imperfections.md\n",
      "Created file: nm-p3/129-fools-and-wise-men.md\n",
      "Created file: nm-p3/130-the-divine-messengers.md\n",
      "Created file: nm-p3/131-one-fortunate-attachment.md\n",
      "Created file: nm-p3/132-ananda-and-one-fortunate-attachment.md\n",
      "Created file: nm-p3/133-maha-kaccana-and-one-fortunate-attachment.md\n",
      "Created file: nm-p3/134-lomasakangiya-and-one-fortunate-attachment.md\n",
      "Created file: nm-p3/135-the-shorter-exposition-of-action.md\n",
      "Created file: nm-p3/136-the-greater-exposition-of-action.md\n",
      "Created file: nm-p3/137-the-exposition-of-the-sixfold-base.md\n",
      "Created file: nm-p3/138-the-exposition-of-a-summary.md\n",
      "Created file: nm-p3/139-the-exposition-of-non-conflict.md\n",
      "Created file: nm-p3/140-the-exposition-of-the-elements.md\n",
      "Created file: nm-p3/141-the-exposition-of-the-truths.md\n",
      "Created file: nm-p3/142-the-exposition-of-offerings.md\n",
      "Created file: nm-p3/143-advice-to-anathapinika.md\n",
      "Created file: nm-p3/144-advice-to-channa.md\n",
      "Created file: nm-p3/145-advice-to-punna.md\n",
      "Created file: nm-p3/146-advice-from-nandaka.md\n",
      "Created file: nm-p3/147-the-shorter-discourse-of-advice-to-rahula.md\n",
      "Created file: nm-p3/148-the-six-sets-of-six.md\n",
      "Created file: nm-p3/149-the-great-sixfold-base.md\n",
      "Created file: nm-p3/150-to-the-nagaravindans.md\n",
      "Created file: nm-p3/151-the-purification-of-almsfood.md\n",
      "Created file: nm-p3/152-the-development-of-the-faculties.md\n"
     ]
    }
   ],
   "source": [
    "# step 4. split file for chapter (part 1,2,3)\n",
    "\n",
    "import os\n",
    "import re\n",
    "from slugify import slugify\n",
    "\n",
    "def split_markdown_file(input_file, output_folder):\n",
    "    \"\"\"\n",
    "    Splits a Markdown file into smaller files based on top-level headers (#).\n",
    "\n",
    "    Args:\n",
    "        input_file: Path to the input Markdown file.\n",
    "        output_folder: Path to the folder where the output files will be saved.\n",
    "    \"\"\"\n",
    "\n",
    "    if not os.path.exists(output_folder):\n",
    "        os.makedirs(output_folder)\n",
    "\n",
    "    try:\n",
    "        with open(input_file, 'r', encoding='utf-8') as f:\n",
    "            content = f.read()\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: Input file '{input_file}' not found.\")\n",
    "        return\n",
    "    except Exception as e:\n",
    "        print(f\"Error reading file: {e}\")\n",
    "        return\n",
    "\n",
    "\n",
    "    # Simpler regex to just find the header lines\n",
    "    pattern = r'^(#\\s+\\d+\\s+.*)$'\n",
    "    lines = content.splitlines()\n",
    "    sections = []\n",
    "    current_section = []\n",
    "\n",
    "    for line in lines:\n",
    "        if re.match(pattern, line):\n",
    "            if current_section:\n",
    "                sections.append(current_section)\n",
    "            current_section = [line]\n",
    "        else:\n",
    "            current_section.append(line)\n",
    "    sections.append(current_section)  # Add the last section\n",
    "\n",
    "\n",
    "    for section in sections:\n",
    "        if not section:  # Skip empty sections\n",
    "            continue\n",
    "\n",
    "        header_line = section[0]\n",
    "        body = \"\\n\".join(section[1:]).strip()\n",
    "\n",
    "        # Extract number and the rest of the title\n",
    "        match = re.match(r'^#\\s+(\\d+)\\s+(.*)$', header_line)\n",
    "        if not match:\n",
    "            print(f\"Warning: Could not parse header: {header_line}\")\n",
    "            continue  # Skip this section if header is malformed\n",
    "        number = match.group(1).strip()\n",
    "        title_text = match.group(2).strip()\n",
    "\n",
    "\n",
    "        # Split the title text by \"Sutta\"\n",
    "        parts = title_text.split(\"Sutta\")\n",
    "        if len(parts) < 2:\n",
    "            print(f\"Warning: 'Sutta' not found in header: {header_line}\")\n",
    "            pali_title = title_text  # Use the full title as a fallback\n",
    "            english_title = \"\"\n",
    "\n",
    "        else:\n",
    "            pali_prefix = parts[0].strip()\n",
    "            pali_title = f\"{pali_prefix} Sutta\"\n",
    "            english_title = \"Sutta\".join(parts[1:]).strip()  # Join in case \"Sutta\" appears in the English title\n",
    "\n",
    "\n",
    "        # Create the new header\n",
    "        new_header = f\"# {number} {english_title}\\n***({pali_title})***\"\n",
    "\n",
    "        # Create slug\n",
    "        slug = slugify(english_title)\n",
    "        #slug = re.sub(r'[^\\w-]', '', slug)   # Remove characters that are not word characters or hyphens\n",
    "\n",
    "        # Create file name\n",
    "        file_number = f\"{int(number):03}\"\n",
    "        file_name = f\"{file_number}-{slug}.md\"\n",
    "        file_path = os.path.join(output_folder, file_name)\n",
    "\n",
    "        # Write the content to the new file\n",
    "        try:\n",
    "            with open(file_path, 'w', encoding='utf-8') as outfile:\n",
    "                outfile.write(new_header + \"\\n\\n\") #add 2 new line.\n",
    "                outfile.write(body)\n",
    "            print(f\"Created file: {file_path}\")\n",
    "        except Exception as e:\n",
    "           print(f\"Error writing to file '{file_path}': {e}\")\n",
    "\n",
    "\n",
    "filename=\"trungbo-eng-nanamoli-bodhi.part3.md\"\n",
    "\n",
    "split_markdown_file(filename, \"nm-p3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# step 4. split file for preface (part 0)\n",
    "\n",
    "import os\n",
    "import re\n",
    "from slugify import slugify  # Install with: pip install python-slugify\n",
    "\n",
    "def split_markdown(input_file, output_folder):\n",
    "    \"\"\"\n",
    "    Splits a Markdown file into multiple files based on H1 headings (# Title).\n",
    "    Filenames are slugified versions of the titles.\n",
    "\n",
    "    Args:\n",
    "        input_file: The path to the input Markdown file.\n",
    "        output_folder: The directory to save the output files.\n",
    "    \"\"\"\n",
    "\n",
    "    if not os.path.exists(output_folder):\n",
    "        os.makedirs(output_folder)\n",
    "\n",
    "    try:\n",
    "        with open(input_file, 'r', encoding='utf-8') as f:\n",
    "            content = f.read()\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: Input file '{input_file}' not found.\")\n",
    "        return\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred while reading the file: {e}\")\n",
    "        return\n",
    "\n",
    "    pattern = r\"^\\s*#\\s+(.+)\\s*$\"\n",
    "    parts = re.split(pattern, content, flags=re.MULTILINE)\n",
    "\n",
    "    if len(parts) < 2:\n",
    "        print(\"No H1 headings found.  No files created.\")\n",
    "        return\n",
    "\n",
    "    file_counter = 0\n",
    "    first_file_name = os.path.join(output_folder, f\"{file_counter}.introduction.md\")\n",
    "    with open(first_file_name, \"w\", encoding='utf-8') as outfile:\n",
    "        outfile.write(parts[0].strip())\n",
    "\n",
    "    for i in range(1, len(parts) - 1, 2):\n",
    "        title = parts[i].strip()\n",
    "        content_after_title = parts[i + 1].strip()\n",
    "        #content_after_title = content_after_title.replace(\"\\n\", \"\\n\\n\")\n",
    "        file_counter += 1\n",
    "        slugified_title = slugify(title)  # Slugify the title\n",
    "        file_name = os.path.join(output_folder, f\"{file_counter}.{slugified_title}.md\")\n",
    "        with open(file_name, 'w', encoding='utf-8') as outfile:\n",
    "            outfile.write(f\"# {title}\\n\\n{content_after_title}\")\n",
    "\n",
    "    print(f\"Successfully split '{input_file}' into {file_counter} files in '{output_folder}'.\")\n",
    "\n",
    "\n",
    "\n",
    "input_filename = \"nm.p4.md\"\n",
    "output_directory = \"nm-p4\"\n",
    "split_markdown(input_filename, output_directory)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Could not determine number for first segment. skipping it\n",
      "Saved Sutta 1 to ./nm-p4/notes/001.md\n",
      "Saved Sutta 2 to ./nm-p4/notes/002.md\n",
      "Saved Sutta 3 to ./nm-p4/notes/003.md\n",
      "Saved Sutta 4 to ./nm-p4/notes/004.md\n",
      "Saved Sutta 5 to ./nm-p4/notes/005.md\n",
      "Saved Sutta 6 to ./nm-p4/notes/006.md\n",
      "Saved Sutta 7 to ./nm-p4/notes/007.md\n",
      "Saved Sutta 8 to ./nm-p4/notes/008.md\n",
      "Saved Sutta 9 to ./nm-p4/notes/009.md\n",
      "Saved Sutta 10 to ./nm-p4/notes/010.md\n",
      "Saved Sutta 11 to ./nm-p4/notes/011.md\n",
      "Saved Sutta 12 to ./nm-p4/notes/012.md\n",
      "Saved Sutta 13 to ./nm-p4/notes/013.md\n",
      "Saved Sutta 14 to ./nm-p4/notes/014.md\n",
      "Saved Sutta 15 to ./nm-p4/notes/015.md\n",
      "Saved Sutta 16 to ./nm-p4/notes/016.md\n",
      "Saved Sutta 17 to ./nm-p4/notes/017.md\n",
      "Saved Sutta 18 to ./nm-p4/notes/018.md\n",
      "Saved Sutta 19 to ./nm-p4/notes/019.md\n",
      "Saved Sutta 20 to ./nm-p4/notes/020.md\n",
      "Saved Sutta 21 to ./nm-p4/notes/021.md\n",
      "Saved Sutta 22 to ./nm-p4/notes/022.md\n",
      "Saved Sutta 23 to ./nm-p4/notes/023.md\n",
      "Saved Sutta 24 to ./nm-p4/notes/024.md\n",
      "Saved Sutta 25 to ./nm-p4/notes/025.md\n",
      "Saved Sutta 26 to ./nm-p4/notes/026.md\n",
      "Saved Sutta 27 to ./nm-p4/notes/027.md\n",
      "Saved Sutta 28 to ./nm-p4/notes/028.md\n",
      "Saved Sutta 29 to ./nm-p4/notes/029.md\n",
      "Saved Sutta 30 to ./nm-p4/notes/030.md\n",
      "Saved Sutta 31 to ./nm-p4/notes/031.md\n",
      "Saved Sutta 32 to ./nm-p4/notes/032.md\n",
      "Saved Sutta 33 to ./nm-p4/notes/033.md\n",
      "Saved Sutta 34 to ./nm-p4/notes/034.md\n",
      "Saved Sutta 35 to ./nm-p4/notes/035.md\n",
      "Saved Sutta 36 to ./nm-p4/notes/036.md\n",
      "Saved Sutta 37 to ./nm-p4/notes/037.md\n",
      "Saved Sutta 38 to ./nm-p4/notes/038.md\n",
      "Saved Sutta 39 to ./nm-p4/notes/039.md\n",
      "Saved Sutta 40 to ./nm-p4/notes/040.md\n",
      "Saved Sutta 41 to ./nm-p4/notes/041.md\n",
      "Saved Sutta 43 to ./nm-p4/notes/043.md\n",
      "Saved Sutta 44 to ./nm-p4/notes/044.md\n",
      "Saved Sutta 46 to ./nm-p4/notes/046.md\n",
      "Saved Sutta 47 to ./nm-p4/notes/047.md\n",
      "Saved Sutta 48 to ./nm-p4/notes/048.md\n",
      "Saved Sutta 49 to ./nm-p4/notes/049.md\n",
      "Saved Sutta 50 to ./nm-p4/notes/050.md\n",
      "Saved Sutta 51 to ./nm-p4/notes/051.md\n",
      "Saved Sutta 52 to ./nm-p4/notes/052.md\n",
      "Saved Sutta 53 to ./nm-p4/notes/053.md\n",
      "Saved Sutta 54 to ./nm-p4/notes/054.md\n",
      "Saved Sutta 55 to ./nm-p4/notes/055.md\n",
      "Saved Sutta 56 to ./nm-p4/notes/056.md\n",
      "Saved Sutta 57 to ./nm-p4/notes/057.md\n",
      "Saved Sutta 58 to ./nm-p4/notes/058.md\n",
      "Saved Sutta 59 to ./nm-p4/notes/059.md\n",
      "Saved Sutta 60 to ./nm-p4/notes/060.md\n",
      "Saved Sutta 61 to ./nm-p4/notes/061.md\n",
      "Saved Sutta 62 to ./nm-p4/notes/062.md\n",
      "Saved Sutta 63 to ./nm-p4/notes/063.md\n",
      "Saved Sutta 64 to ./nm-p4/notes/064.md\n",
      "Saved Sutta 65 to ./nm-p4/notes/065.md\n",
      "Saved Sutta 66 to ./nm-p4/notes/066.md\n",
      "Saved Sutta 67 to ./nm-p4/notes/067.md\n",
      "Saved Sutta 68 to ./nm-p4/notes/068.md\n",
      "Saved Sutta 69 to ./nm-p4/notes/069.md\n",
      "Saved Sutta 70 to ./nm-p4/notes/070.md\n",
      "Saved Sutta 71 to ./nm-p4/notes/071.md\n",
      "Saved Sutta 72 to ./nm-p4/notes/072.md\n",
      "Saved Sutta 73 to ./nm-p4/notes/073.md\n",
      "Saved Sutta 74 to ./nm-p4/notes/074.md\n",
      "Saved Sutta 75 to ./nm-p4/notes/075.md\n",
      "Saved Sutta 76 to ./nm-p4/notes/076.md\n",
      "Saved Sutta 77 to ./nm-p4/notes/077.md\n",
      "Saved Sutta 78 to ./nm-p4/notes/078.md\n",
      "Saved Sutta 79 to ./nm-p4/notes/079.md\n",
      "Saved Sutta 80 to ./nm-p4/notes/080.md\n",
      "Saved Sutta 81 to ./nm-p4/notes/081.md\n",
      "Saved Sutta 82 to ./nm-p4/notes/082.md\n",
      "Saved Sutta 83 to ./nm-p4/notes/083.md\n",
      "Saved Sutta 84 to ./nm-p4/notes/084.md\n",
      "Saved Sutta 85 to ./nm-p4/notes/085.md\n",
      "Saved Sutta 86 to ./nm-p4/notes/086.md\n",
      "Saved Sutta 87 to ./nm-p4/notes/087.md\n",
      "Saved Sutta 88 to ./nm-p4/notes/088.md\n",
      "Saved Sutta 89 to ./nm-p4/notes/089.md\n",
      "Saved Sutta 90 to ./nm-p4/notes/090.md\n",
      "Saved Sutta 91 to ./nm-p4/notes/091.md\n",
      "Saved Sutta 92 to ./nm-p4/notes/092.md\n",
      "Saved Sutta 93 to ./nm-p4/notes/093.md\n",
      "Saved Sutta 94 to ./nm-p4/notes/094.md\n",
      "Saved Sutta 95 to ./nm-p4/notes/095.md\n",
      "Saved Sutta 96 to ./nm-p4/notes/096.md\n",
      "Saved Sutta 97 to ./nm-p4/notes/097.md\n",
      "Saved Sutta 98 to ./nm-p4/notes/098.md\n",
      "Saved Sutta 99 to ./nm-p4/notes/099.md\n",
      "Saved Sutta 100 to ./nm-p4/notes/100.md\n",
      "Saved Sutta 101 to ./nm-p4/notes/101.md\n",
      "Saved Sutta 102 to ./nm-p4/notes/102.md\n",
      "Saved Sutta 103 to ./nm-p4/notes/103.md\n",
      "Saved Sutta 104 to ./nm-p4/notes/104.md\n",
      "Saved Sutta 105 to ./nm-p4/notes/105.md\n",
      "Saved Sutta 106 to ./nm-p4/notes/106.md\n",
      "Saved Sutta 107 to ./nm-p4/notes/107.md\n",
      "Saved Sutta 108 to ./nm-p4/notes/108.md\n",
      "Saved Sutta 109 to ./nm-p4/notes/109.md\n",
      "Saved Sutta 110 to ./nm-p4/notes/110.md\n",
      "Saved Sutta 111 to ./nm-p4/notes/111.md\n",
      "Saved Sutta 112 to ./nm-p4/notes/112.md\n",
      "Saved Sutta 113 to ./nm-p4/notes/113.md\n",
      "Saved Sutta 114 to ./nm-p4/notes/114.md\n",
      "Saved Sutta 115 to ./nm-p4/notes/115.md\n",
      "Saved Sutta 116 to ./nm-p4/notes/116.md\n",
      "Saved Sutta 117 to ./nm-p4/notes/117.md\n",
      "Saved Sutta 118 to ./nm-p4/notes/118.md\n",
      "Saved Sutta 119 to ./nm-p4/notes/119.md\n",
      "Saved Sutta 120 to ./nm-p4/notes/120.md\n",
      "Saved Sutta 121 to ./nm-p4/notes/121.md\n",
      "Saved Sutta 122 to ./nm-p4/notes/122.md\n",
      "Saved Sutta 123 to ./nm-p4/notes/123.md\n",
      "Saved Sutta 124 to ./nm-p4/notes/124.md\n",
      "Saved Sutta 125 to ./nm-p4/notes/125.md\n",
      "Saved Sutta 126 to ./nm-p4/notes/126.md\n",
      "Saved Sutta 127 to ./nm-p4/notes/127.md\n",
      "Saved Sutta 128 to ./nm-p4/notes/128.md\n",
      "Saved Sutta 129 to ./nm-p4/notes/129.md\n",
      "Saved Sutta 130 to ./nm-p4/notes/130.md\n",
      "Saved Sutta 131 to ./nm-p4/notes/131.md\n",
      "Saved Sutta 133 to ./nm-p4/notes/133.md\n",
      "Saved Sutta 134 to ./nm-p4/notes/134.md\n",
      "Saved Sutta 135 to ./nm-p4/notes/135.md\n",
      "Saved Sutta 136 to ./nm-p4/notes/136.md\n",
      "Saved Sutta 137 to ./nm-p4/notes/137.md\n",
      "Saved Sutta 138 to ./nm-p4/notes/138.md\n",
      "Saved Sutta 139 to ./nm-p4/notes/139.md\n",
      "Saved Sutta 140 to ./nm-p4/notes/140.md\n",
      "Saved Sutta 141 to ./nm-p4/notes/141.md\n",
      "Saved Sutta 142 to ./nm-p4/notes/142.md\n",
      "Saved Sutta 143 to ./nm-p4/notes/143.md\n",
      "Saved Sutta 144 to ./nm-p4/notes/144.md\n",
      "Saved Sutta 145 to ./nm-p4/notes/145.md\n",
      "Saved Sutta 146 to ./nm-p4/notes/146.md\n",
      "Saved Sutta 147 to ./nm-p4/notes/147.md\n",
      "Saved Sutta 148 to ./nm-p4/notes/148.md\n",
      "Saved Sutta 149 to ./nm-p4/notes/149.md\n",
      "Saved Sutta 151 to ./nm-p4/notes/151.md\n",
      "Saved Sutta 152 to ./nm-p4/notes/152.md\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import os\n",
    "import argparse\n",
    "\n",
    "\n",
    "def split_note(filename, output_folder):\n",
    "    \"\"\"\n",
    "    Splits a Markdown file by SUTTA titles (e.g., \"SUTTA 15\") and saves each\n",
    "    Sutta into a separate file.\n",
    "\n",
    "    Args:\n",
    "        filename: The path to the input Markdown file.\n",
    "        output_folder: The path to the directory where the split files\n",
    "            will be saved.\n",
    "    \"\"\"\n",
    "\n",
    "    try:\n",
    "        with open(filename, 'r', encoding='utf-8') as f:\n",
    "            content = f.read()\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: File '{filename}' not found.\")\n",
    "        return\n",
    "    except Exception as e:\n",
    "        print(f\"Error reading file '{filename}': {e}\")\n",
    "        return\n",
    "\n",
    "    # Create the output directory if it doesn't exist.\n",
    "    if not os.path.exists(output_folder):\n",
    "        os.makedirs(output_folder)\n",
    "\n",
    "    # Regular expression to find \"SUTTA <number>\" titles.  We use \\s+ to\n",
    "    # handle multiple spaces between \"SUTTA\" and the number, and make it\n",
    "    # case-insensitive.\n",
    "    sutta_pattern = re.compile(r\"^SUTTA\\s+(\\d+)$\", re.MULTILINE | re.IGNORECASE)\n",
    "\n",
    "    # Find all Sutta start positions.  Add a \"start\" at the beginning\n",
    "    # of the file, and an implicit \"end\" at the end of the file.\n",
    "    sutta_starts = [0]  # Add the beginning of the file\n",
    "    for match in sutta_pattern.finditer(content):\n",
    "        sutta_starts.append(match.start())\n",
    "    sutta_starts.append(len(content)) # add the end of file\n",
    "\n",
    "    # Extract and save each Sutta.\n",
    "    for i in range(len(sutta_starts) - 1):\n",
    "        start = sutta_starts[i]\n",
    "        end = sutta_starts[i+1]\n",
    "        sutta_text = content[start:end]\n",
    "\n",
    "        # Extract the Sutta number.\n",
    "        match = sutta_pattern.search(sutta_text)\n",
    "\n",
    "        if match:\n",
    "             sutta_number_str = match.group(1)\n",
    "        elif i == 0: # if first sutta is not found, check it from input.\n",
    "            match_first = re.search(r\"^SUTTA\\s+(\\d+)\", sutta_text, re.IGNORECASE)\n",
    "            if match_first:\n",
    "               sutta_number_str = match_first.group(1)\n",
    "            else:\n",
    "                print(f\"Warning: Could not determine number for first segment. skipping it\")\n",
    "                continue\n",
    "        else:\n",
    "            print(f\"Warning: Could not extract Sutta number between {start} and {end}. Skipping this section.\")\n",
    "            continue\n",
    "\n",
    "        sutta_number = int(sutta_number_str)\n",
    "        # Format the filename.\n",
    "        output_filename = os.path.join(output_folder, f\"{sutta_number:03}.md\")\n",
    "\n",
    "        # Save the Sutta to a file.\n",
    "        try:\n",
    "            with open(output_filename, 'w', encoding='utf-8') as outfile:\n",
    "                outfile.write(sutta_text)\n",
    "            print(f\"Saved Sutta {sutta_number} to {output_filename}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error writing to file '{output_filename}': {e}\")\n",
    "\n",
    "\n",
    "\n",
    "filename = './nm-p4/3.notes.md'\n",
    "output_folder = './nm-p4/notes'\n",
    "split_note(filename, output_folder)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

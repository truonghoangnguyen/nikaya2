{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created PDF with pages 502 to 1092 at ../.docsource/kinhtuongung/tuongungbokinh-2.pdf\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "export const OCR_SYSTEM_PROMPT = `\n",
    "Convert the following document to markdown.\n",
    "Return only the markdown with no explanation text. Do not include delimiters like '''markdown or '''html.\n",
    "\n",
    "RULES:\n",
    "  - You must include all information on the page. Do not exclude headers, footers, charts, infographics, or subtext.\n",
    "  - Return tables in an HTML format.\n",
    "  - Logos should be wrapped in brackets. Ex: <logo>Coca-Cola<logo>\n",
    "  - Watermarks should be wrapped in brackets. Ex: <watermark>OFFICIAL COPY<watermark>\n",
    "  - Page numbers should be wrapped in brackets. Ex: <page_number>14<page_number> or <page_number>9/22<page_number>\n",
    "  - Prefer using ☐ and ☑ for check boxes.\n",
    "`;\n",
    "\n",
    "export const JSON_EXTRACTION_SYSTEM_PROMPT = `\n",
    "  Extract the following JSON schema from the text and images if provided.\n",
    "  Return only the JSON with no explanation text.\n",
    "`;\n",
    "\n",
    "export const IMAGE_EXTRACTION_SYSTEM_PROMPT = `\n",
    "  Extract the following JSON schema from the image.\n",
    "  Return only the JSON with no explanation text.\n",
    "`;\n",
    "\"\"\"\n",
    "\n",
    "from PyPDF2 import PdfReader, PdfWriter\n",
    "import os\n",
    "\n",
    "def extract_pdf_pages(input_pdf, output_pdf, start_page, end_page):\n",
    "    \"\"\"\n",
    "    Extracts a range of pages from a PDF file and saves them as a new PDF.\n",
    "\n",
    "    Args:\n",
    "        input_pdf: Path to the input PDF file\n",
    "        output_pdf: Path to save the extracted PDF file\n",
    "        start_page: Starting page number (0-based index)\n",
    "        end_page: Ending page number (0-based index, inclusive)\n",
    "    \"\"\"\n",
    "    reader = PdfReader(input_pdf)\n",
    "    writer = PdfWriter()\n",
    "\n",
    "    # Validate page range\n",
    "    total_pages = len(reader.pages)\n",
    "    if end_page >= total_pages:\n",
    "        end_page = total_pages - 1\n",
    "    if start_page < 0 or end_page >= total_pages or start_page > end_page:\n",
    "        raise ValueError(f\"Invalid page range. PDF has {total_pages} pages.\")\n",
    "\n",
    "    # Add selected pages to the new PDF\n",
    "    for page_num in range(start_page, end_page + 1):\n",
    "        writer.add_page(reader.pages[page_num])\n",
    "\n",
    "    # Save the new PDF\n",
    "    with open(output_pdf, \"wb\") as output_file:\n",
    "        writer.write(output_file)\n",
    "\n",
    "    print(f\"Created PDF with pages {start_page+1} to {end_page+1} at {output_pdf}\")\n",
    "\n",
    "filename = '../../docsource/trungbo-eng-nanamoli-bodhi2.out1.pdf'\n",
    "# 1, 4, 58\n",
    "# 2, 59, 73\n",
    "# 3, 435, 814\n",
    "\n",
    "args = {\"output_pdf\": '../.docsource/kinhtuongung/tuongungbokinh-2.pdf', \"start_page\": 501, \"end_page\": 5000}\n",
    "p0=\"https://drive.usercontent.google.com/u/0/uc?id=1dOGYtQABuCOlVdY8WmLlZJShG1jCYKkm&export=download\"\n",
    "# args = {\"output_pdf\": f'../../docsource/trungbo-eng-nanamoli-bodhi.part{2}.pdf', \"start_page\": 435, \"end_page\": 814}\n",
    "p1 = \"https://drive.usercontent.google.com/u/0/uc?id=1OQyCzluVkULUSNFrhMcEm1dSrc_TFbt0&export=download\"\n",
    "# args = {\"output_pdf\": f'../../docsource/trungbo-eng-nanamoli-bodhi.part{3}.pdf', \"start_page\": 819, \"end_page\": 1143}\n",
    "extract_pdf_pages('../.docsource/kinhtuongung/tuongungbokinh.pdf', **args)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# step 2 : mistral for ocr\n",
    "import os\n",
    "from mistralai import Mistral\n",
    "import os\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "\n",
    "load_dotenv(find_dotenv(), override=True)\n",
    "\n",
    "api_key = os.environ.get(\"MISTRALAI_KEY\")\n",
    "client = Mistral(api_key=api_key)\n",
    "\n",
    "ocr_response = client.ocr.process(\n",
    "    model=\"mistral-ocr-latest\",\n",
    "    document={\n",
    "        \"type\": \"document_url\",\n",
    "        \"document_url\": \"https://drive.usercontent.google.com/uc?id=1IEQ6bIZTBhqfR6LodrjcBZhDyiQIIsdn&export=download\"\n",
    "    },\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 (5) Wealth in Brief\n",
      "\"Bhikkhus, there are these seven kinds of wealth. What seven? The wealth of faith, the wealth of virtuous behavior, the wealth of moral shame, the wealth of moral dread, the wealth of learning, the wealth of generosity, and the wealth of wisdom. [5] These are the seven kinds of wealth.\"\n",
      "\n",
      "The wealth of faith, the wealth of virtuous behavior, the wealth of moral shame and moral dread, the wealth of learning and generosity, with wisdom, the seventh kind of wealth:\n",
      "when one has these seven kinds of wealth, whether a woman or a man, they say that one is not poor, that one's life is not lived in vain.\n",
      "\n",
      "Therefore an intelligent person, remembering the Buddhas' teaching, should be intent on faith and virtuous behawic confidence and vision of the Dhamma.\n",
      "\n",
      "# 6 (6) Wealth in Detail \n",
      "\n",
      "\"Bhikkhus, there are these seven kinds of wealth. What seven? The wealth of faith, the wealth of virtuous behavior, the wealth of moral shame, the wealth of moral dread, the wealth of learning, the wealth of generosity, and the wealth of wisdom.\n",
      "(1) \"And what, bhikkhus, is the wealth of faith? Here, a noble disciple is endowed with faith. He places faith in the enlightenment of the Tathāgata thus: 'The Blessed One is an arahant... the Enlightened One, the Blessed One.' This is called the wealth of faith.\n",
      "(2) \"And what is the wealth of virtuous behavior? Here, a noble disciple abstains from the destruction of life, abstains from taking what is not given, abstains from sexual misconduct, abstains from false speech, abstains from liquor, wine, and intoxicants, the basis for heedlessness. This is called the wealth of virtuous behavior.\n",
      "(3) \"And what is the wealth of moral shame? Here, a noble disciple has a sense of moral shame; he is ashamed of bodily, ver-\n"
     ]
    }
   ],
   "source": [
    "print(ocr_response.pages[0].markdown)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# step 3: write to markdown\n",
    "import re\n",
    "def is_new_paragraph_start(first_line):\n",
    "    \"\"\"Kiểm tra xem dòng đầu tiên có vẻ là bắt đầu đoạn văn mới không.\"\"\"\n",
    "    if not first_line: # Trang trống\n",
    "        return True\n",
    "    first_char = first_line[0]\n",
    "    return first_char.isupper() or first_char.isdigit() or first_char == '#' # Đơn giản: bắt đầu bằng chữ hoa có thể là đoạn mới (cần tinh chỉnh)\n",
    "\n",
    "output_file=\"The_Numerical_Discourses_of_the_BuddhaAnguttara_NikayaBodhi2012_p2.md\"\n",
    "\n",
    "def replace_newline_split_join_no_generator(text):\n",
    "    \"\"\"\n",
    "    Split and join version, but without using a generator expression.\n",
    "    Potentially a bit more readable, and may be slightly more performant for\n",
    "    *very* large strings (due to avoiding repeated string concatenation)\n",
    "    \"\"\"\n",
    "    parts = text.split(\"\\n\\n\")\n",
    "    modified_parts = []\n",
    "    for part in parts:\n",
    "        modified_parts.append(part.replace(\"\\n\", \"\\n\\n\"))\n",
    "    return \"\\n\\n\".join(modified_parts)\n",
    "\n",
    "with open(output_file, \"w\", encoding=\"utf-8\") as f:\n",
    "    for i, page in enumerate(ocr_response.pages):\n",
    "        txt = page.markdown# .replace(\"\\n\", \"\\n\\n\")\n",
    "        txt = replace_newline_split_join_no_generator(txt)\n",
    "        f.write(txt)\n",
    "        if i < len(ocr_response.pages) - 1: # Không thêm vào trang cuối\n",
    "            next_page_first_line = ocr_response.pages[i+1].markdown.strip().splitlines()[0] if ocr_response.pages[i+1].markdown.strip().splitlines() else \"\"\n",
    "            if is_new_paragraph_start(next_page_first_line):\n",
    "                f.write(\"\\n\\n\") # Hoặc f.write(\"\\n---\\n\")\n",
    "            else:\n",
    "                f.write(\"\\n\") # Hoặc không thêm gì cả, tùy thử nghiệm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# step 4. split file for chapter (part 1,2,3)\n",
    "\n",
    "import os\n",
    "import re\n",
    "from slugify import slugify\n",
    "\n",
    "def split_markdown_file(input_file, output_folder):\n",
    "    \"\"\"\n",
    "    Splits a Markdown file into smaller files based on top-level headers (#).\n",
    "\n",
    "    Args:\n",
    "        input_file: Path to the input Markdown file.\n",
    "        output_folder: Path to the folder where the output files will be saved.\n",
    "    \"\"\"\n",
    "\n",
    "    if not os.path.exists(output_folder):\n",
    "        os.makedirs(output_folder)\n",
    "\n",
    "    try:\n",
    "        with open(input_file, 'r', encoding='utf-8') as f:\n",
    "            content = f.read()\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: Input file '{input_file}' not found.\")\n",
    "        return\n",
    "    except Exception as e:\n",
    "        print(f\"Error reading file: {e}\")\n",
    "        return\n",
    "\n",
    "\n",
    "    # Simpler regex to just find the header lines\n",
    "    pattern = r'^(#\\s+\\d+\\s+.*)$'\n",
    "    lines = content.splitlines()\n",
    "    sections = []\n",
    "    current_section = []\n",
    "\n",
    "    for line in lines:\n",
    "        if re.match(pattern, line):\n",
    "            if current_section:\n",
    "                sections.append(current_section)\n",
    "            current_section = [line]\n",
    "        else:\n",
    "            current_section.append(line)\n",
    "    sections.append(current_section)  # Add the last section\n",
    "\n",
    "\n",
    "    for section in sections:\n",
    "        if not section:  # Skip empty sections\n",
    "            continue\n",
    "\n",
    "        header_line = section[0]\n",
    "        body = \"\\n\".join(section[1:]).strip()\n",
    "\n",
    "        # Extract number and the rest of the title\n",
    "        match = re.match(r'^#\\s+(\\d+)\\s+(.*)$', header_line)\n",
    "        if not match:\n",
    "            print(f\"Warning: Could not parse header: {header_line}\")\n",
    "            continue  # Skip this section if header is malformed\n",
    "        number = match.group(1).strip()\n",
    "        title_text = match.group(2).strip()\n",
    "\n",
    "\n",
    "        # Split the title text by \"Sutta\"\n",
    "        parts = title_text.split(\"Sutta\")\n",
    "        if len(parts) < 2:\n",
    "            print(f\"Warning: 'Sutta' not found in header: {header_line}\")\n",
    "            pali_title = title_text  # Use the full title as a fallback\n",
    "            english_title = \"\"\n",
    "\n",
    "        else:\n",
    "            pali_prefix = parts[0].strip()\n",
    "            pali_title = f\"{pali_prefix} Sutta\"\n",
    "            english_title = \"Sutta\".join(parts[1:]).strip()  # Join in case \"Sutta\" appears in the English title\n",
    "\n",
    "\n",
    "        # Create the new header\n",
    "        new_header = f\"# {number} {english_title}\\n***({pali_title})***\"\n",
    "\n",
    "        # Create slug\n",
    "        slug = slugify(english_title)\n",
    "        #slug = re.sub(r'[^\\w-]', '', slug)   # Remove characters that are not word characters or hyphens\n",
    "\n",
    "        # Create file name\n",
    "        file_number = f\"{int(number):03}\"\n",
    "        file_name = f\"{file_number}-{slug}.md\"\n",
    "        file_path = os.path.join(output_folder, file_name)\n",
    "\n",
    "        # Write the content to the new file\n",
    "        try:\n",
    "            with open(file_path, 'w', encoding='utf-8') as outfile:\n",
    "                outfile.write(new_header + \"\\n\\n\") #add 2 new line.\n",
    "                outfile.write(body)\n",
    "            print(f\"Created file: {file_path}\")\n",
    "        except Exception as e:\n",
    "           print(f\"Error writing to file '{file_path}': {e}\")\n",
    "\n",
    "\n",
    "filename=\"trungbo-eng-nanamoli-bodhi.part2.md\"\n",
    "\n",
    "split_markdown_file(filename, \"majjhima_output\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully split 'nm.p0.md' into 23 files in 'nm-p0'.\n"
     ]
    }
   ],
   "source": [
    "# step 4. split file for preface (part 0)\n",
    "\n",
    "import os\n",
    "import re\n",
    "from slugify import slugify  # Install with: pip install python-slugify\n",
    "\n",
    "def split_markdown(input_file, output_folder):\n",
    "    \"\"\"\n",
    "    Splits a Markdown file into multiple files based on H1 headings (# Title).\n",
    "    Filenames are slugified versions of the titles.\n",
    "\n",
    "    Args:\n",
    "        input_file: The path to the input Markdown file.\n",
    "        output_folder: The directory to save the output files.\n",
    "    \"\"\"\n",
    "\n",
    "    if not os.path.exists(output_folder):\n",
    "        os.makedirs(output_folder)\n",
    "\n",
    "    try:\n",
    "        with open(input_file, 'r', encoding='utf-8') as f:\n",
    "            content = f.read()\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: Input file '{input_file}' not found.\")\n",
    "        return\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred while reading the file: {e}\")\n",
    "        return\n",
    "\n",
    "    pattern = r\"^\\s*#\\s+(.+)\\s*$\"\n",
    "    parts = re.split(pattern, content, flags=re.MULTILINE)\n",
    "\n",
    "    if len(parts) < 2:\n",
    "        print(\"No H1 headings found.  No files created.\")\n",
    "        return\n",
    "\n",
    "    file_counter = 0\n",
    "    first_file_name = os.path.join(output_folder, f\"{file_counter}.introduction.md\")\n",
    "    with open(first_file_name, \"w\", encoding='utf-8') as outfile:\n",
    "        outfile.write(parts[0].strip())\n",
    "\n",
    "    for i in range(1, len(parts) - 1, 2):\n",
    "        title = parts[i].strip()\n",
    "        content_after_title = parts[i + 1].strip()\n",
    "        #content_after_title = content_after_title.replace(\"\\n\", \"\\n\\n\")\n",
    "        file_counter += 1\n",
    "        slugified_title = slugify(title)  # Slugify the title\n",
    "        file_name = os.path.join(output_folder, f\"{file_counter}.{slugified_title}.md\")\n",
    "        with open(file_name, 'w', encoding='utf-8') as outfile:\n",
    "            outfile.write(f\"# {title}\\n\\n{content_after_title}\")\n",
    "\n",
    "    print(f\"Successfully split '{input_file}' into {file_counter} files in '{output_folder}'.\")\n",
    "\n",
    "\n",
    "\n",
    "input_filename = \"nm.p0.md\"\n",
    "output_directory = \"nm-p0\"\n",
    "split_markdown(input_filename, output_directory)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
